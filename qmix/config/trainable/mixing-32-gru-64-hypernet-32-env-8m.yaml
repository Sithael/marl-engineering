architecture-directive:
  drqn_configuration:
    model:
      type: dict
      choice: {
        "observation_size": 80,
        "n_actions": 14,
        "embedding_size": 64,
        "hidden_state_size": 128,
        "n_q_values": 14,
        }
    training:
      lr:
        type: float
        choice: 0.0005
      gamma:
        type: float
        choice: 0.99
      epsilon_max:
        type: float
        choice: 1.0
      epsilon_min:
        type: float
        choice: 0.05
      num_epsilon_dec_steps:
        type: int
        choice: 50_000
      target_network_update_schedule:
        type: int
        choice: 200
  hypernetwork_configuration:
    bias_updates:
      model:
        type: dict
        choice: {
          "state_representation_size": 168,
          "hidden_layer_size": 32,
          }
    weight_updates:
      model:
        type: dict
        choice: {
          "state_representation_size": 168,
          "hidden_layer_size": 32,
          }
  mixing_network_configuration:
    model:
      choice: {
        "n_q_values": 14,
        "hidden_layer_size": 32,
        }
  device_configuration:
    accelerator:
      type: str
      choice: "cpu"

environment-directive:
  prefix:
    type: string
    choice: "8m"
  num_agents:
    type: int
    choice: 8
  space_params_configuration:
    state_shape:
      type: int
      choice: 168
    single_agent_obs_shape:
      type: int
      choice: 80
    n_actions:
      type: int
      choice: 14
    episode_limit:
      type: int
      choice: 120
